{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('reviews.tsv', sep='\\t')\n",
    "\n",
    "# Preprocessing (if needed)\n",
    "# For simplicity, let's assume the data is clean and doesn't require preprocessing.\n",
    "\n",
    "# Feature Extraction\n",
    "X = df['Review']\n",
    "y = df['Label']\n",
    "\n",
    "# Bag of Words (BoW)\n",
    "bow_vectorizer = CountVectorizer()\n",
    "X_bow = bow_vectorizer.fit_transform(X)\n",
    "\n",
    "# TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
    "\n",
    "# Word2Vec\n",
    "sentences = [review.split() for review in X]\n",
    "word2vec_model = Word2Vec(sentences, min_count=1)\n",
    "\n",
    "def word_averaging(wv, words):\n",
    "    all_words, mean = set(), []\n",
    "    for word in words:\n",
    "        if isinstance(word, np.ndarray):\n",
    "            mean.append(word)\n",
    "        elif word in wv.wv.vocab:\n",
    "            mean.append(wv[word])\n",
    "            all_words.add(wv.vocab[word].index)\n",
    "\n",
    "    if not mean:\n",
    "        return np.zeros(wv.vector_size,)\n",
    "    mean = np.array(mean).mean(axis=0)\n",
    "    return mean\n",
    "\n",
    "def word_averaging_list(wv, text_list):\n",
    "    return np.vstack([word_averaging(wv, post) for post in text_list])\n",
    "\n",
    "X_word2vec = word_averaging_list(word2vec_model, sentences)\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train_bow, X_test_bow, y_train, y_test = train_test_split(X_bow, y, test_size=0.2, random_state=42)\n",
    "X_train_tfidf, X_test_tfidf, _, _ = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "X_train_word2vec, X_test_word2vec, _, _ = train_test_split(X_word2vec, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model Training\n",
    "# Naive Bayes\n",
    "nb_classifier_bow = MultinomialNB()\n",
    "nb_classifier_bow.fit(X_train_bow, y_train)\n",
    "\n",
    "nb_classifier_tfidf = MultinomialNB()\n",
    "nb_classifier_tfidf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# KNN\n",
    "knn_classifier_word2vec = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_classifier_word2vec.fit(X_train_word2vec, y_train)\n",
    "\n",
    "# Model Evaluation\n",
    "# Naive Bayes\n",
    "nb_pred_bow = nb_classifier_bow.predict(X_test_bow)\n",
    "nb_pred_tfidf = nb_classifier_tfidf.predict(X_test_tfidf)\n",
    "\n",
    "# KNN\n",
    "knn_pred_word2vec = knn_classifier_word2vec.predict(X_test_word2vec)\n",
    "\n",
    "print(\"Naive Bayes (BoW) Accuracy:\", accuracy_score(y_test, nb_pred_bow))\n",
    "print(\"Naive Bayes (TF-IDF) Accuracy:\", accuracy_score(y_test, nb_pred_tfidf))\n",
    "print(\"KNN (Word2Vec) Accuracy:\", accuracy_score(y_test, knn_pred_word2vec))\n",
    "\n",
    "print(\"\\nClassification Report for Naive Bayes (BoW):\\n\", classification_report(y_test, nb_pred_bow))\n",
    "print(\"\\nClassification Report for Naive Bayes (TF-IDF):\\n\", classification_report(y_test, nb_pred_tfidf))\n",
    "print(\"\\nClassification Report for KNN (Word2Vec):\\n\", classification_report(y_test, knn_pred_word2vec))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "\n",
    "# Load the trained Word2Vec model\n",
    "w2v = Word2Vec.load('./trained-word2vec-studentReviews.model')\n",
    "\n",
    "def sentence_to_vector(sentence, model):\n",
    "    words = sentence.split()\n",
    "    word_vectors = [model.wv[word] for word in words if word in model.wv]\n",
    "    if not word_vectors:  # If the sentence contains no words in the model's vocabulary\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean(word_vectors, axis=0)\n",
    "\n",
    "# Create vectors for all sentences\n",
    "X_vectors = np.array([sentence_to_vector(sentence, w2v) for sentence in X])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the Gaussian Naive Bayes model\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Train the model\n",
    "gnb.fit(X_train_vecs, Y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "Y_pred = gnb.predict(X_test_vecs)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Including graphs in your Jupyter Notebook to show the analysis and comparison between various algorithms is a great way to visualize the performance of different models. You can use libraries like matplotlib and seaborn to create these visualizations. Here is how you can add such graphs:\n",
    "\n",
    "Plot Accuracy Comparison:\n",
    "\n",
    "Create a bar plot to compare the accuracy of different models.\n",
    "Confusion Matrix:\n",
    "\n",
    "Plot confusion matrices to show the performance of each classifier in more detail.\n",
    "ROC Curves:\n",
    "\n",
    "Plot ROC curves to compare the true positive rates and false positive rates of the classifiers.\n",
    "Example Code for Visualizations\n",
    "First, ensure you have the necessary libraries installed:\n",
    "\n",
    "bash\n",
    "Copy code\n",
    "pip install matplotlib seaborn scikit-learn\n",
    "Then, you can use the following code to include the visualizations:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "\n",
    "# Assuming you have already calculated these accuracy scores\n",
    "accuracy_scores = {\n",
    "    'Naive Bayes (BoW)': accuracy_score(Y_test, nb_pred_bow),\n",
    "    'Naive Bayes (TF-IDF)': accuracy_score(Y_test, nb_pred_tfidf),\n",
    "    'Naive Bayes (Word2Vec)': accuracy_score(Y_test, nb_pred_w2v),\n",
    "    'KNN (BoW)': accuracy_score(Y_test, knn_pred_bow),\n",
    "    'KNN (TF-IDF)': accuracy_score(Y_test, knn_pred_tfidf),\n",
    "    'KNN (Word2Vec)': accuracy_score(Y_test, knn_pred_w2v),\n",
    "    # Include other models if you have added them, e.g., SVM, Random Forest\n",
    "}\n",
    "\n",
    "# Plotting the accuracy scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=list(accuracy_scores.keys()), y=list(accuracy_scores.values()))\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.title('Model Accuracy Comparison')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Plotting confusion matrices\n",
    "def plot_confusion_matrix(y_true, y_pred, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Plot confusion matrices for each model\n",
    "plot_confusion_matrix(Y_test, nb_pred_bow, 'Confusion Matrix: Naive Bayes (BoW)')\n",
    "plot_confusion_matrix(Y_test, nb_pred_tfidf, 'Confusion Matrix: Naive Bayes (TF-IDF)')\n",
    "plot_confusion_matrix(Y_test, nb_pred_w2v, 'Confusion Matrix: Naive Bayes (Word2Vec)')\n",
    "plot_confusion_matrix(Y_test, knn_pred_bow, 'Confusion Matrix: KNN (BoW)')\n",
    "plot_confusion_matrix(Y_test, knn_pred_tfidf, 'Confusion Matrix: KNN (TF-IDF)')\n",
    "plot_confusion_matrix(Y_test, knn_pred_w2v, 'Confusion Matrix: KNN (Word2Vec)')\n",
    "\n",
    "# Plotting ROC curves\n",
    "def plot_roc_curve(y_true, y_pred_proba, title):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "# For ROC curves, you need predicted probabilities, not labels\n",
    "# Assuming the classifiers support the `predict_proba` method\n",
    "# If not, use `decision_function` method for classifiers like SVM\n",
    "\n",
    "# Plot ROC curves for each model\n",
    "plot_roc_curve(Y_test, nb_bow.predict_proba(X_test_bow)[:, 1], 'ROC Curve: Naive Bayes (BoW)')\n",
    "plot_roc_curve(Y_test, nb_tfidf.predict_proba(X_test_tfidf)[:, 1], 'ROC Curve: Naive Bayes (TF-IDF)')\n",
    "plot_roc_curve(Y_test, nb_w2v.predict_proba(X_test_w2v_scaled)[:, 1], 'ROC Curve: Naive Bayes (Word2Vec)')\n",
    "plot_roc_curve(Y_test, knn_bow.predict_proba(X_test_bow_reduced)[:, 1], 'ROC Curve: KNN (BoW)')\n",
    "plot_roc_curve(Y_test, knn_tfidf.predict_proba(X_test_tfidf_reduced)[:, 1], 'ROC Curve: KNN (TF-IDF)')\n",
    "plot_roc_curve(Y_test, knn_w2v.predict_proba(X_test_w2v_scaled)[:, 1], 'ROC Curve: KNN (Word2Vec)')\n",
    "Explanation\n",
    "Bar Plot for Accuracy Scores:\n",
    "\n",
    "sns.barplot is used to create a bar plot of the accuracy scores of different models.\n",
    "The x-axis represents different models, and the y-axis represents the accuracy scores.\n",
    "Confusion Matrix:\n",
    "\n",
    "confusion_matrix from sklearn.metrics is used to calculate the confusion matrix.\n",
    "sns.heatmap is used to plot the confusion matrix.\n",
    "ROC Curves:\n",
    "\n",
    "roc_curve and auc from sklearn.metrics are used to compute the ROC curve and the area under the curve (AUC).\n",
    "A plot is generated to show the ROC curve for each model.\n",
    "By adding these visualizations, you can better understand and compare the performance of your different models. Adjust the code as needed based on your specific models and data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "\n",
    "# Assuming you have already calculated these accuracy scores\n",
    "accuracy_scores = {\n",
    "    'Naive Bayes (BoW)': accuracy_score(Y_test, nb_pred_bow),\n",
    "    'Naive Bayes (TF-IDF)': accuracy_score(Y_test, nb_pred_tfidf),\n",
    "    'Naive Bayes (Word2Vec)': accuracy_score(Y_test, nb_pred_w2v),\n",
    "    'KNN (BoW)': accuracy_score(Y_test, knn_pred_bow),\n",
    "    'KNN (TF-IDF)': accuracy_score(Y_test, knn_pred_tfidf),\n",
    "    'KNN (Word2Vec)': accuracy_score(Y_test, knn_pred_w2v),\n",
    "    # Include other models if you have added them, e.g., SVM, Random Forest\n",
    "}\n",
    "\n",
    "# Plotting the accuracy scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=list(accuracy_scores.keys()), y=list(accuracy_scores.values()))\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.title('Model Accuracy Comparison')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Plotting confusion matrices\n",
    "def plot_confusion_matrix(y_true, y_pred, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Plot confusion matrices for each model\n",
    "plot_confusion_matrix(Y_test, nb_pred_bow, 'Confusion Matrix: Naive Bayes (BoW)')\n",
    "plot_confusion_matrix(Y_test, nb_pred_tfidf, 'Confusion Matrix: Naive Bayes (TF-IDF)')\n",
    "plot_confusion_matrix(Y_test, nb_pred_w2v, 'Confusion Matrix: Naive Bayes (Word2Vec)')\n",
    "plot_confusion_matrix(Y_test, knn_pred_bow, 'Confusion Matrix: KNN (BoW)')\n",
    "plot_confusion_matrix(Y_test, knn_pred_tfidf, 'Confusion Matrix: KNN (TF-IDF)')\n",
    "plot_confusion_matrix(Y_test, knn_pred_w2v, 'Confusion Matrix: KNN (Word2Vec)')\n",
    "\n",
    "# Plotting ROC curves\n",
    "def plot_roc_curve(y_true, y_pred_proba, title):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "# For ROC curves, you need predicted probabilities, not labels\n",
    "# Assuming the classifiers support the `predict_proba` method\n",
    "# If not, use `decision_function` method for classifiers like SVM\n",
    "\n",
    "# Plot ROC curves for each model\n",
    "plot_roc_curve(Y_test, nb_bow.predict_proba(X_test_bow)[:, 1], 'ROC Curve: Naive Bayes (BoW)')\n",
    "plot_roc_curve(Y_test, nb_tfidf.predict_proba(X_test_tfidf)[:, 1], 'ROC Curve: Naive Bayes (TF-IDF)')\n",
    "plot_roc_curve(Y_test, nb_w2v.predict_proba(X_test_w2v_scaled)[:, 1], 'ROC Curve: Naive Bayes (Word2Vec)')\n",
    "plot_roc_curve(Y_test, knn_bow.predict_proba(X_test_bow_reduced)[:, 1], 'ROC Curve: KNN (BoW)')\n",
    "plot_roc_curve(Y_test, knn_tfidf.predict_proba(X_test_tfidf_reduced)[:, 1], 'ROC Curve: KNN (TF-IDF)')\n",
    "plot_roc_curve(Y_test, knn_w2v.predict_proba(X_test_w2v_scaled)[:, 1], 'ROC Curve: KNN (Word2Vec)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using Bag of Words: 0.9295212765957447\n",
      "Accuracy using TF-IDF: 0.9680851063829787\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# Loading sample dataset for sentiment analysis (you can replace it with your own dataset)\n",
    "dataset = fetch_20newsgroups(subset='all', categories=['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med'])\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset.data, dataset.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature extraction using Bag of Words (CountVectorizer)\n",
    "count_vectorizer = CountVectorizer()\n",
    "X_train_counts = count_vectorizer.fit_transform(X_train)\n",
    "X_test_counts = count_vectorizer.transform(X_test)\n",
    "\n",
    "# Feature extraction using TF-IDF (TfidfVectorizer)\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# SVM classifier\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "\n",
    "# Training and predicting using Bag of Words features\n",
    "svm_classifier.fit(X_train_counts, y_train)\n",
    "y_pred_counts = svm_classifier.predict(X_test_counts)\n",
    "accuracy_counts = accuracy_score(y_test, y_pred_counts)\n",
    "print(\"Accuracy using Bag of Words:\", accuracy_counts)\n",
    "\n",
    "# Training and predicting using TF-IDF features\n",
    "svm_classifier.fit(X_train_tfidf, y_train)\n",
    "y_pred_tfidf = svm_classifier.predict(X_test_tfidf)\n",
    "accuracy_tfidf = accuracy_score(y_test, y_pred_tfidf)\n",
    "print(\"Accuracy using TF-IDF:\", accuracy_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.preprocessing import scale\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming you have your data and labels\n",
    "# X = data\n",
    "# y = labels\n",
    "\n",
    "# Example data (replace with your actual data)\n",
    "X = [\"I love this movie\", \"I hate this movie\", \"This movie is okay\"]\n",
    "y = [1, 0, 1]\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature Extraction Methods\n",
    "vectorizers = {\n",
    "    'Bag of Words': CountVectorizer(),\n",
    "    'TF-IDF': TfidfVectorizer()\n",
    "}\n",
    "\n",
    "# Word2Vec (Assuming pre-trained model or training your own model)\n",
    "w2v_model = Word2Vec(sentences=[sentence.split() for sentence in X_train], vector_size=100, window=5, min_count=1, workers=4)\n",
    "def word2vec_features(sentences, model):\n",
    "    features = []\n",
    "    for sentence in sentences:\n",
    "        words = sentence.split()\n",
    "        feature_vector = np.mean([model.wv[word] for word in words if word in model.wv], axis=0)\n",
    "        features.append(feature_vector)\n",
    "    return scale(np.array(features))\n",
    "\n",
    "# Classifiers\n",
    "classifiers = {\n",
    "    'Naive Bayes': MultinomialNB(),\n",
    "    'k-NN': KNeighborsClassifier(),\n",
    "    'SVM': SVC(probability=True)  # SVC for ROC Curve\n",
    "}\n",
    "\n",
    "# Initialize dictionaries to store results\n",
    "results = {}\n",
    "\n",
    "for vec_name, vectorizer in vectorizers.items():\n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "    \n",
    "    for clf_name, classifier in classifiers.items():\n",
    "        classifier.fit(X_train_vec, y_train)\n",
    "        y_pred = classifier.predict(X_test_vec)\n",
    "        \n",
    "        # Evaluate\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average='weighted')\n",
    "        recall = recall_score(y_test, y_pred, average='weighted')\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        \n",
    "        # Store results\n",
    "        results[(vec_name, clf_name)] = {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'y_pred': y_pred,\n",
    "            'classifier': classifier,\n",
    "            'X_test_vec': X_test_vec\n",
    "        }\n",
    "\n",
    "# Word2Vec\n",
    "X_train_w2v = word2vec_features(X_train, w2v_model)\n",
    "X_test_w2v = word2vec_features(X_test, w2v_model)\n",
    "\n",
    "for clf_name, classifier in classifiers.items():\n",
    "    classifier.fit(X_train_w2v, y_train)\n",
    "    y_pred = classifier.predict(X_test_w2v)\n",
    "    \n",
    "    # Evaluate\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    # Store results\n",
    "    results[('Word2Vec', clf_name)] = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'y_pred': y_pred,\n",
    "        'classifier': classifier,\n",
    "        'X_test_vec': X_test_w2v\n",
    "    }\n",
    "\n",
    "# Display results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Review</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>good and interesting</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>This class is very helpful to me. Currently, I...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>like!Prof and TAs are helpful and the discussi...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Easy to follow and includes a lot basic and im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Really nice teacher!I could got the point eazl...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                             Review  Label\n",
       "0   0                               good and interesting      5\n",
       "1   1  This class is very helpful to me. Currently, I...      5\n",
       "2   2  like!Prof and TAs are helpful and the discussi...      5\n",
       "3   3  Easy to follow and includes a lot basic and im...      5\n",
       "4   4  Really nice teacher!I could got the point eazl...      4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('reviews.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "5    79173\n",
      "4    18054\n",
      "3     5071\n",
      "1     2469\n",
      "2     2251\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "label_counts = df[\"Label\"].value_counts()\n",
    "\n",
    "# Print or visualize the counts\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "above shows that the datset is biased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Certainly! Below is a modified version of a Jupyter Notebook incorporating hyperparameter tuning using Grid Search, data augmentation using SMOTE, and undersampling for handling the imbalanced dataset.\n",
    "\n",
    "Step-by-Step Guide\n",
    "1. Install Necessary Libraries\n",
    "Make sure you have the required libraries installed. You can install them using pip if they are not already installed:\n",
    "\n",
    "bash\n",
    "Copy code\n",
    "!pip install imbalanced-learn scikit-learn\n",
    "!pip install pandas numpy\n",
    "2. Import Libraries\n",
    "python\n",
    "Copy code\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "3. Load Your Dataset\n",
    "Replace your_data.csv with the path to your dataset.\n",
    "\n",
    "python\n",
    "Copy code\n",
    "# Load dataset\n",
    "df = pd.read_csv('your_data.csv')\n",
    "X = df['text']\n",
    "y = df['label']\n",
    "4. Vectorize Text Data\n",
    "python\n",
    "Copy code\n",
    "# Vectorize text data\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_vect = vectorizer.fit_transform(X)\n",
    "5. Data Augmentation\n",
    "python\n",
    "Copy code\n",
    "# Define oversampling and undersampling strategies\n",
    "over = SMOTE(sampling_strategy=0.5)\n",
    "under = RandomUnderSampler(sampling_strategy=0.8)\n",
    "\n",
    "# Create a pipeline with SMOTE and RandomUnderSampler\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "# Apply pipeline to the data\n",
    "X_res, y_res = pipeline.fit_resample(X_vect, y)\n",
    "6. Split Data\n",
    "python\n",
    "Copy code\n",
    "# Split the resampled data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42, stratify=y_res)\n",
    "7. Hyperparameter Tuning with Grid Search\n",
    "python\n",
    "Copy code\n",
    "# Initialize the model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Set up the grid search with cross-validation\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "grid_search = GridSearchCV(model, param_grid, scoring='f1', cv=cv, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Print best parameters\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "8. Evaluate the Model\n",
    "python\n",
    "Copy code\n",
    "# Predict on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Print classification report and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import xgboost as xgb\n",
    "\n",
    "# Assuming `df` is your DataFrame with 'text' and 'label' columns\n",
    "# Load your dataset\n",
    "df = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# Data Preprocessing\n",
    "X = df['text']\n",
    "y = df['label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Vectorization using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_vect = vectorizer.fit_transform(X_train)\n",
    "X_test_vect = vectorizer.transform(X_test)\n",
    "\n",
    "# Handling Imbalanced Dataset using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X_train_vect, y_train)\n",
    "\n",
    "# Model Training with Grid Search\n",
    "# Here we use RandomForest as an example, you can replace it with other classifiers like SVM, XGBoost, etc.\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Using StratifiedKFold for cross-validation\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Grid Search for Hyperparameter Tuning\n",
    "grid_search = GridSearchCV(model, param_grid, scoring='f1', cv=cv, n_jobs=-1)\n",
    "grid_search.fit(X_res, y_res)\n",
    "\n",
    "# Best Model Evaluation\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test_vect)\n",
    "\n",
    "# Evaluation Metrics\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Optional: Save the best model for future use\n",
    "import joblib\n",
    "joblib.dump(best_model, 'best_model.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier detection, PCA and SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# Ensure that the dataset contains the required columns\n",
    "assert 'ID' in data.columns, \"The dataset must contain an 'ID' column.\"\n",
    "assert 'Review' in data.columns, \"The dataset must contain a 'Review' column.\"\n",
    "assert 'Labels' in data.columns, \"The dataset must contain a 'Labels' column.\"\n",
    "assert 'cleaned_reviews' in data.columns, \"The dataset must contain a 'cleaned_reviews' column.\"\n",
    "\n",
    "# Calculate Z-scores for Labels (assuming Labels is the sentiment score)\n",
    "data['z_score'] = (data['Labels'] - data['Labels'].mean()) / data['Labels'].std()\n",
    "\n",
    "# Identify outliers based on Z-score\n",
    "outliers_z = data[np.abs(data['z_score']) > 3]\n",
    "data = data[np.abs(data['z_score']) <= 3]\n",
    "\n",
    "# Visualize Labels without outliers\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=data['Labels'])\n",
    "plt.title('Boxplot of Labels (Sentiment Scores) after Removing Z-score Outliers')\n",
    "plt.show()\n",
    "\n",
    "print(\"Removed outliers based on Z-score:\")\n",
    "print(outliers_z[['ID', 'Review', 'Labels', 'z_score']])\n",
    "\n",
    "# Convert cleaned_reviews data to TF-IDF features\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(data['cleaned_reviews'])\n",
    "\n",
    "# Apply TruncatedSVD for dimensionality reduction\n",
    "svd = TruncatedSVD(n_components=10)\n",
    "svd_features = svd.fit_transform(tfidf_matrix)\n",
    "\n",
    "# Use Local Outlier Factor (LOF) to detect outliers in the reduced feature space\n",
    "lof = LocalOutlierFactor(n_neighbors=20, contamination=0.1)\n",
    "outlier_labels = lof.fit_predict(svd_features)\n",
    "\n",
    "# Add the outlier labels to the dataset\n",
    "data['outlier_lof'] = outlier_labels\n",
    "\n",
    "# Visualize the SVD-reduced features with outliers\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(svd_features[:, 0], svd_features[:, 1], c=outlier_labels, cmap='coolwarm', marker='o')\n",
    "plt.title('SVD-reduced Features with LOF Outliers')\n",
    "plt.xlabel('Component 1')\n",
    "plt.ylabel('Component 2')\n",
    "plt.show()\n",
    "\n",
    "# Display the outliers detected by LOF\n",
    "outliers_lof = data[data['outlier_lof'] == -1]\n",
    "print(\"Outliers detected by LOF:\")\n",
    "print(outliers_lof[['ID', 'Review', 'Labels', 'outlier_lof']])\n",
    "\n",
    "# Remove LOF outliers from the dataset\n",
    "data = data[data['outlier_lof'] != -1]\n",
    "\n",
    "# Apply SMOTE to balance the dataset\n",
    "smote = SMOTE()\n",
    "tfidf_matrix_resampled, labels_resampled = smote.fit_resample(tfidf_matrix[data.index], data['Labels'])\n",
    "\n",
    "# Optionally, apply TruncatedSVD again to the resampled data for visualization\n",
    "svd_resampled = TruncatedSVD(n_components=2)\n",
    "svd_features_resampled = svd_resampled.fit_transform(tfidf_matrix_resampled)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(svd_features_resampled[:, 0], svd_features_resampled[:, 1], c=labels_resampled, cmap='viridis', marker='o')\n",
    "plt.title('SVD-reduced Features after Applying SMOTE')\n",
    "plt.xlabel('Component 1')\n",
    "plt.ylabel('Component 2')\n",
    "plt.show()\n",
    "\n",
    "# Final cleaned and balanced dataset\n",
    "# Note: tfidf_matrix_resampled is still in sparse format\n",
    "cleaned_data = csr_matrix(tfidf_matrix_resampled)  # Keep the data in sparse format\n",
    "labels_resampled = np.array(labels_resampled).reshape(-1, 1)  # Convert labels to a 2D array\n",
    "\n",
    "\n",
    "print(\"Cleaned and balanced dataset:\")\n",
    "print(cleaned_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#savig the data\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "\n",
    "# Assuming `cleaned_data` is your sparse TF-IDF matrix and `labels_resampled` is your labels array\n",
    "\n",
    "# Save the sparse matrix in .npz format (or choose another sparse format)\n",
    "sp.save_npz('cleaned_data.npz', cleaned_data)\n",
    "\n",
    "# Save the labels as a NumPy array (.npy)\n",
    "np.save('labels_resampled.npy', labels_resampled)\n",
    "\n",
    "print(\"Cleaned and balanced dataset saved successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
